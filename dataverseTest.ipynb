{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "The purpose of this document is to create a Dataverse API testing notebook. See [_about_dataverseTest.md](./_about_dataverseTest.md) for information about configuring and running this notebook, and the technical details about the notebook (since we didn't want to bog down the notebook with instructions if you know Python)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dataverse Collection\n",
    "\n",
    "### Configuration\n",
    "\n",
    "Using the Dataverse starter object `DATAVERSE_COLLECTION_START` in our configuration file we will create a new collection through the API https://guides.dataverse.org/en/5.13/api/native-api.html#create-a-dataverse-collection. Luckily we do not need to follow the API documentation that instructs users to create a separate JSON file for use with the API endpoint. Since we added the JSON to our main configuration file we can simply reference the object in the `json` parameter of our request. We will place this collection under the root 'parent' collection.\n",
    "\n",
    "### Retrieving our collection info\n",
    "\n",
    "Since we already have our starter collection information defined in our main `_config_dataverseTest.json` file, there is no need to save the collection information sent back from the creation of our collection. We can always use the `ViewCollection()` method in our worker script to retrieve the collection information as long as we at least know our collection alias. \n",
    "\n",
    "### Issue\n",
    "\n",
    "Note: If you use a GET request instead of a POST request to the API endpoint, the action may appear to be successful but it will simply be returning the Dataverse collection of the main parent collection, and NOT create a new collection for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Finished ObjDvApi init\n",
      "Finished installing and importing modules for the _config_dataverseTest.json environment\n"
     ]
    }
   ],
   "source": [
    "# run the _installer_dataverseTest.py script and import our _worker_modTest.py script\n",
    "import _installer_dataverseTest\n",
    "%load_ext autoreload\n",
    "%autoreload all\n",
    "from _worker_dataverseTest import Worker\n",
    "# we need the 'autoreload' above if we are actively making changes to the worker.py module and want to reload any changes to the module without restarting the notebook kernel\n",
    "# NOTE: if we make changes to the worker script or configuration we need to rerun this code block for the notebook to use the new edits\n",
    "objWorker = Worker(\"_config_dataverseTest.json\") # initialize our Worker object; we should only need to call this once for the notebook session (working with 'demo' configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the notebook code\n",
    "\n",
    "The code blocks in this notebook are intentionally brief because most users are not concerned with what the code looks like (at least initially). If you want to know what the scripts do then review the .py files that we imported into this notebook. However we will briefly describe a line of code so you have a general idea of what is happening behind the scenes.\n",
    "\n",
    "The `objWorker.ObjDvApi.DvCreateCollection()` command for example, runs the `DvCreateCollection()` method, which is found in the `ObjDvApi` object, and makes a Dataverse API request to create a new repository/collection. The `ObjDvApi` is simply defined in an external Python file which contains reusable methods for working with the Dataverse API. We use this same class for all of our datasets, so keeping the methods in a single file for reuse is better than manually adding into the code of each of our datasets and making our working code script more densely worded than it needs to be.\n",
    "\n",
    "### The objWorker\n",
    "\n",
    "The `objWorker` is the object that we customize for each dataset and simply acts as a template for importing different classes/objects we want to attach to it. For instance, we attach the `ObjDvApi` to our `objWorker` object so whatever functionality exists in the `ObjDvApi` class can be used in our `objWorker` class. The `.` between `objWorker.ObjDvApi` simply represents that `ObjDvApi` is an extension of `objWorker`. An analogy would be adding a dustpan to a broom (or `broom.dustpan`) to extend the functionality of the broom, so the broom can now be used to pick up dust and not simply push it around.\n",
    "\n",
    "Below are some simple code commands to set up a Dataverse collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objWorker.ObjDvApi.createCollection()  # initialize a new collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start viewCollection\n",
      "making request: https://demo-dataverse.rdmc.unc.edu/api/dataverses/jocoknow\n",
      "----------------------------------------\n",
      "json= {'status': 'OK', 'data': {'id': 391, 'alias': 'jocoknow', 'name': 'JoCoKnow', 'affiliation': 'University of North Carolina - Chapel Hill', 'dataverseContacts': [{'displayOrder': 0, 'contactEmail': 'w.patrick.gale@unc.edu'}, {'displayOrder': 1, 'contactEmail': 'student@example.edu'}], 'permissionRoot': True, 'description': 'JoCoOA and JoCoHS data repository', 'dataverseType': 'RESEARCH_PROJECTS', 'ownerId': 1, 'creationDate': '2024-08-19T19:23:03Z'}}\n",
      "headers= {'Date': 'Mon, 19 Aug 2024 22:06:46 GMT', 'Server': 'Apache/2.4.37 (Rocky Linux) OpenSSL/1.1.1k', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'PUT, GET, POST, DELETE, OPTIONS', 'Access-Control-Allow-Headers': 'Accept, Content-Type, X-Dataverse-Key, Range', 'Access-Control-Expose-Headers': 'Accept-Ranges, Content-Range, Content-Encoding', 'Content-Type': 'application/json;charset=UTF-8', 'Content-Length': '424', 'Keep-Alive': 'timeout=5, max=100', 'Connection': 'Keep-Alive'}\n",
      "response status= 200\n",
      "end viewCollection\n"
     ]
    }
   ],
   "source": [
    "objWorker.ObjDvApi.viewCollection()  # view information on our dataverse collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objWorker.ObjDvApi.deleteCollection()  # delete our dataverse collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start viewCollectionContents\n",
      "making request: https://demo-dataverse.rdmc.unc.edu/api/dataverses/jocoknow/contents\n",
      "----------------------------------------\n",
      "json= {'status': 'OK', 'data': [{'id': 392, 'identifier': 'DMO/J8P4TN', 'persistentUrl': 'https://doi.org/10.33563/DMO/J8P4TN', 'protocol': 'doi', 'authority': '10.33563', 'publisher': 'UNC Demo Dataverse', 'storageIdentifier': 's3://10.33563/DMO/J8P4TN', 'type': 'dataset'}]}\n",
      "headers= {'Date': 'Mon, 19 Aug 2024 22:04:41 GMT', 'Server': 'Apache/2.4.37 (Rocky Linux) OpenSSL/1.1.1k', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'PUT, GET, POST, DELETE, OPTIONS', 'Access-Control-Allow-Headers': 'Accept, Content-Type, X-Dataverse-Key, Range', 'Access-Control-Expose-Headers': 'Accept-Ranges, Content-Range, Content-Encoding', 'Content-Type': 'application/json;charset=UTF-8', 'Content-Length': '252', 'Keep-Alive': 'timeout=5, max=100', 'Connection': 'Keep-Alive'}\n",
      "response status= 200\n",
      "end viewCollectionContents\n"
     ]
    }
   ],
   "source": [
    "objWorker.ObjDvApi.viewCollectionContents()  # view dataverse collection contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset\n",
    "\n",
    "Using the https://guides.dataverse.org/en/5.13/_downloads/4e04c8120d51efab20e480c6427f139c/dataset-create-new-all-default-fields.json referenced in https://guides.dataverse.org/en/5.13/api/native-api.html#create-a-dataset-in-a-dataverse-collection, will be our dataset template. We simply add this JSON object to our `_config_dataverseTest.json` file under the `DATAVERSE_DATASET` constant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start createDataset\n",
      "start createDataset\n",
      "making request: https://demo-dataverse.rdmc.unc.edu/api/dataverses/jocoknow/datasets\n",
      "----------------------------------------\n",
      "json= {'status': 'OK', 'data': {'id': 400, 'persistentId': 'doi:10.33563/DMO/MVP3EY'}}\n",
      "headers= {'Date': 'Mon, 19 Aug 2024 22:20:31 GMT', 'Server': 'Apache/2.4.37 (Rocky Linux) OpenSSL/1.1.1k', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'PUT, GET, POST, DELETE, OPTIONS', 'Access-Control-Allow-Headers': 'Accept, Content-Type, X-Dataverse-Key, Range', 'Access-Control-Expose-Headers': 'Accept-Ranges, Content-Range, Content-Encoding', 'Location': 'https://demo-dataverse.rdmc.unc.edu/datasets/400', 'Content-Type': 'application/json;charset=UTF-8', 'Content-Length': '74', 'Keep-Alive': 'timeout=5, max=100', 'Connection': 'Keep-Alive'}\n",
      "response status= 201\n",
      "{'status': 'OK', 'data': {'id': 400, 'persistentId': 'doi:10.33563/DMO/MVP3EY'}}\n"
     ]
    },
    {
     "ename": "UnsupportedOperation",
     "evalue": "not readable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mobjWorker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# create a partial dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# NOTE: we need the JSON object of the full dataset initialization (waiting from RDMC)\u001b[39;00m\n",
      "File \u001b[0;32m~/work/_worker_dataverseTest.py:65\u001b[0m, in \u001b[0;36mWorker.createDataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(r\u001b[38;5;241m.\u001b[39mjson())\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrDOCKER_WORKING_DIR\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_config_dataverseTest.json\u001b[39m\u001b[38;5;124m\"\u001b[39m), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m jsonFile:   \u001b[38;5;66;03m# read a copy of the metadata\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     objConfig \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjsonFile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     objConfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrDvDATASET_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m objRJson[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     67\u001b[0m     objConfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrDvUrlPersistentId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m objRJson[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpersistentId\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "\u001b[0;31mUnsupportedOperation\u001b[0m: not readable"
     ]
    }
   ],
   "source": [
    "objWorker.createDataset()  # create a partial dataset\n",
    "# NOTE: we need the JSON object of the full dataset initialization (waiting from RDMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start deleteDataset\n",
      "start deleteDatasetDraft\n",
      "making request: https://demo-dataverse.rdmc.unc.edu/api/datasets/399/versions/:draft\n",
      "----------------------------------------\n",
      "json= {'status': 'OK', 'data': {'message': 'Draft version of dataset 399 deleted'}}\n",
      "headers= {'Date': 'Mon, 19 Aug 2024 22:20:23 GMT', 'Server': 'Apache/2.4.37 (Rocky Linux) OpenSSL/1.1.1k', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'PUT, GET, POST, DELETE, OPTIONS', 'Access-Control-Allow-Headers': 'Accept, Content-Type, X-Dataverse-Key, Range', 'Access-Control-Expose-Headers': 'Accept-Ranges, Content-Range, Content-Encoding', 'Content-Type': 'application/json;charset=UTF-8', 'Content-Length': '73', 'Keep-Alive': 'timeout=5, max=100', 'Connection': 'Keep-Alive'}\n",
      "response status= 200\n",
      "end deleteDatasetDraft\n",
      "end deleteDataset\n"
     ]
    }
   ],
   "source": [
    "objWorker.deleteDataset()  # delete dataset draft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fake data\n",
    "\n",
    "Next we need to create some files to test the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objWorker.createTestFiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding files to the dataset\n",
    "\n",
    "We will assume this notebook is only for the handling of a single dataset, we do not need to save the dataset persistentId to our JSON config.\n",
    "\n",
    "See https://guides.dataverse.org/en/5.13/api/native-api.html#add-file-api\n",
    "\n",
    "Before we upload any files to our dataset we need to make sure we have saved the dataset persistentId to our notebook configuration. We will assume each curation notebook applies to one dataset so we only need to track one persistentId per notebook. So in this case, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objWorker.uploadTestFiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue UNCDVSUP-38 (submitted on 8/17)\n",
    "\n",
    "I’m trying to use the JSON from https://guides.dataverse.org/en/5.13/_downloads/4e04c8120d51efab20e480c6427f139c/dataset-create-new-all-default-fields.json to create a new dataset in http://demo-dataverse.rdmc.unc.edu .  However I am receiving an error that makes it seem that the JSON properties are incorrectly defined. Below is the response information (with the error message appearing in https://github.com/IQSS/dataverse.harvard.edu/issues/172 ):\n",
    "\n",
    "json= {'status': 'ERROR', 'message': 'Error parsing Json: incorrect multiple   for field productionPlace'}\n",
    "headers= {'Date': 'Sat, 17 Aug 2024 16:09:07 GMT', 'Server': 'Apache/2.4.37 (Rocky Linux) OpenSSL/1.1.1k', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'PUT, GET, POST, DELETE, OPTIONS', 'Access-Control-Allow-Headers': 'Accept, Content-Type, X-Dataverse-Key, Range', 'Access-Control-Expose-Headers': 'Accept-Ranges, Content-Range, Content-Encoding', 'Content-Type': 'application/json;charset=UTF-8', 'Content-Length': '97', 'Connection': 'close'}\n",
    "response status= 400\n",
    "\n",
    "The JSON in question seems to be:\n",
    "\n",
    "{\n",
    "              \"typeName\": \"productionPlace\",\n",
    "              \"multiple\": false,\n",
    "              \"typeClass\": \"primitive\",\n",
    "              \"value\": \"ProductionPlace\"\n",
    "            },\n",
    "\n",
    "The release notes for 5.13 state: \n",
    "\n",
    "Edit the following line to your schema.xml (to indicate that productionPlace is now multiValued='true\"):\n",
    "\n",
    "So I can’t tell if the UNC Dataverse schema simply needs updating or something else is going on. If I set \"multiple\": true, in the JSON then the response is:\n",
    "\n",
    "json= {'status': 'ERROR', 'message': 'Error parsing Json: Invalid values submitted for productionPlace. It should be an array of values.'}\n",
    "\n",
    "…but I do not know how to format the JSON for multiple values.\n",
    "\n",
    "My Python method for creating the dataset is using POST so that should not be the issue.\n",
    "\n",
    "def DvCreateDataset(self):\n",
    "        print(\"start DvCreateDataset\")\n",
    "        strApiEndpoint = '%s/api/dataverses/%s/datasets' % (self.strDATAVERSE_DOMAIN, self._config[\"DATAVERSE_COLLECTION_START\"][\"alias\"])\n",
    "        print('making request: %s' % strApiEndpoint)\n",
    "        objHeaders = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"X-Dataverse-Key\": self.strDATAVERSE_API_TOKEN\n",
    "        }\n",
    "        r = requests.request(\"POST\", strApiEndpoint, json=self._config[\"DATAVERSE_DATASET\"], headers=objHeaders)\n",
    "        self.printResponseInfo(r)\n",
    "        print(\"end DvCreateDataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
